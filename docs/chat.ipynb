{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: langchain_qwq\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatQWQ\n",
    "\n",
    "This will help you getting started with QwQ [chat models](/langchain_qwq/chat_models.py). For detailed documentation of all ChatQwQ features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain-qwq/chat_models/langchain_qwq.chat_models.ChatQwQ.html).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: |  :---: | :---: | :---: |\n",
    "| [ChatQwQ](https://python.langchain.com/api_reference/langchain-qwq/chat_models/langchain_qwq.chat_models.ChatQwQ.html) | [langchain-qwq](https://python.langchain.com/api_reference/langchain-qwq/) | ✅ | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-qwq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qwq?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ✅ | ❌ | ❌ | ❌ | ✅ | ✅ | ✅ | ❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access QwQ models you'll need to create an Alibaba Cloud account, get an API key, and install the `langchain-qwq` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to https://account.alibabacloud.com/login/login.htm?oauth_callback=https%3A%2F%2Fbailian.console.alibabacloud.com%2F%3FapiKey%3D1&lang=en#/api-key to sign up to Alibaba Cloud and generate an API key. Once you've done this set the DASHSCOPE_API_KEY environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:14:51.254437Z",
     "start_time": "2025-05-21T13:14:50.228412Z"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DASHSCOPE_API_KEY\"):\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Enter your Dashscope API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain QwQ integration lives in the `langchain-qwq` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:10:53.105794Z",
     "start_time": "2025-05-21T13:10:52.091760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-qwq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:14:55.273181Z",
     "start_time": "2025-05-21T13:14:54.738828Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_qwq import ChatQwQ\n",
    "\n",
    "llm = ChatQwQ(\n",
    "    model=\"qwq-plus\",\n",
    "    temperature=0,\n",
    "    max_tokens=3_000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "- TODO: Run cells so output can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:15:06.636755Z",
     "start_time": "2025-05-21T13:14:57.854793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>Okay, the user wants me to translate \"I love programming.\" into French. Let me start by recalling the basic translation. The verb \"love\" in this context is \"aimer\" in French, but since it\\'s about liking an activity, maybe \"adorer\" could also work, but \"aimer\" is more common here. The subject is \"I\", which is \"je\" in French. \\n\\nNow, \"programming\" is \"la programmation\". Since it\\'s a gerund after \"aimer\", in French you need to use the infinitive form. So \"programming\" would be \"programmer\". \\n\\nPutting it all together: \"Je aime programmer.\" Wait, but there\\'s a common contraction here. \"Je aime\" should be contracted to \"J\\'aime\". So the correct sentence is \"J\\'aime programmer.\" \\n\\nI should check if there\\'s any other way. Sometimes people might use \"l\\'ordinateur\" or other terms, but no, \"programmer\" is correct. Also, the user didn\\'t specify any context, so the straightforward translation is best. \\n\\nDouble-checking grammar: The structure is correct. The subject pronoun \"je\" becomes \"j\\'\" before a vowel sound, hence the apostrophe. The verb \"aimer\" in first person present is \"aime\", so \"j\\'aime\". The infinitive \"programmer\" follows. \\n\\nNo mistakes there. I think that\\'s the accurate translation.</think>J\\'aime programmer.', additional_kwargs={'reasoning_content': 'Okay, the user wants me to translate \"I love programming.\" into French. Let me start by recalling the basic translation. The verb \"love\" in this context is \"aimer\" in French, but since it\\'s about liking an activity, maybe \"adorer\" could also work, but \"aimer\" is more common here. The subject is \"I\", which is \"je\" in French. \\n\\nNow, \"programming\" is \"la programmation\". Since it\\'s a gerund after \"aimer\", in French you need to use the infinitive form. So \"programming\" would be \"programmer\". \\n\\nPutting it all together: \"Je aime programmer.\" Wait, but there\\'s a common contraction here. \"Je aime\" should be contracted to \"J\\'aime\". So the correct sentence is \"J\\'aime programmer.\" \\n\\nI should check if there\\'s any other way. Sometimes people might use \"l\\'ordinateur\" or other terms, but no, \"programmer\" is correct. Also, the user didn\\'t specify any context, so the straightforward translation is best. \\n\\nDouble-checking grammar: The structure is correct. The subject pronoun \"je\" becomes \"j\\'\" before a vowel sound, hence the apostrophe. The verb \"aimer\" in first person present is \"aime\", so \"j\\'aime\". The infinitive \"programmer\" follows. \\n\\nNo mistakes there. I think that\\'s the accurate translation.'}, response_metadata={'model_name': 'qwq-plus'}, id='run-1d5a815d-a8f7-4655-b98c-560211760093-0', usage_metadata={'input_tokens': 32, 'output_tokens': 308, 'total_tokens': 340, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French.\"\n",
    "        \"Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:15:34.003677Z",
     "start_time": "2025-05-21T13:15:23.572163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>Okay, the user wrote \"I love programming.\" and wants it translated to German. Let me start by recalling the basic translation. \"I love\" is \"Ich liebe\" in German. Then \"programming\" – the German word for that is \"Programmieren\". So putting it together, \"Ich liebe Programmieren.\" \\n\\nWait, but in German, sometimes the verb position can be tricky. Let me double-check the sentence structure. The main clause typically has the verb in the second position. Here, since it\\'s a simple statement, the structure \"Ich liebe Programmieren\" should be correct. \\n\\nHmm, another thought: sometimes in German, the noun form might be used with a preposition, but in this case, \"lieben\" can take the accusative case directly. So \"Programmieren\" is a neuter noun, and the accusative doesn\\'t change its form here. So \"Programmieren\" is correct.\\n\\nAlternatively, could it be \"die Programmierung\"? But \"Programmierung\" is more like \"the process of programming\" whereas \"Programmieren\" is the gerund form, which is more commonly used in this context. So \"Ich liebe Programmieren\" is better.\\n\\nIs there any other way to phrase it? Maybe \"Ich liebe es, zu programmieren.\" which translates to \"I love to program.\" That\\'s also correct, but the user might prefer the direct translation using the noun. Since the original uses \"programming\" as a noun, sticking with \"Programmieren\" is more accurate.\\n\\nSo the best translation is \"Ich liebe Programmieren.\" I should also consider if there are any regional variations, but in standard German, this should be acceptable. No need for formal vs. informal here since it\\'s a statement without context. Alright, confident with this answer.</think>Ich liebe Programmieren.', additional_kwargs={'reasoning_content': 'Okay, the user wrote \"I love programming.\" and wants it translated to German. Let me start by recalling the basic translation. \"I love\" is \"Ich liebe\" in German. Then \"programming\" – the German word for that is \"Programmieren\". So putting it together, \"Ich liebe Programmieren.\" \\n\\nWait, but in German, sometimes the verb position can be tricky. Let me double-check the sentence structure. The main clause typically has the verb in the second position. Here, since it\\'s a simple statement, the structure \"Ich liebe Programmieren\" should be correct. \\n\\nHmm, another thought: sometimes in German, the noun form might be used with a preposition, but in this case, \"lieben\" can take the accusative case directly. So \"Programmieren\" is a neuter noun, and the accusative doesn\\'t change its form here. So \"Programmieren\" is correct.\\n\\nAlternatively, could it be \"die Programmierung\"? But \"Programmierung\" is more like \"the process of programming\" whereas \"Programmieren\" is the gerund form, which is more commonly used in this context. So \"Ich liebe Programmieren\" is better.\\n\\nIs there any other way to phrase it? Maybe \"Ich liebe es, zu programmieren.\" which translates to \"I love to program.\" That\\'s also correct, but the user might prefer the direct translation using the noun. Since the original uses \"programming\" as a noun, sticking with \"Programmieren\" is more accurate.\\n\\nSo the best translation is \"Ich liebe Programmieren.\" I should also consider if there are any regional variations, but in standard German, this should be acceptable. No need for formal vs. informal here since it\\'s a statement without context. Alright, confident with this answer.'}, response_metadata={'model_name': 'qwq-plus'}, id='run-49980a69-c195-434b-93c7-1347ed7430cf-0', usage_metadata={'input_tokens': 28, 'output_tokens': 378, 'total_tokens': 406, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates\"\n",
    "            \"{input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3218d0e685e47a",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "We can also use structured output with QwQ and Qwen models. This is useful when we want to extract specific information from the model's response. For example, if we want to extract the translation and the confidence score of the translation, we can define a structured output schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe685eee2c9bbec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:16:56.667197Z",
     "start_time": "2025-05-21T13:16:50.838080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranslationOutput(translation='Ich liebe Programmierung.', confidence=0.9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class TranslationOutput(BaseModel):\n",
    "    translation: str\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "llm_with_structured_output = llm.with_structured_output(TranslationOutput)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates\"\n",
    "            \"{input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm_with_structured_output\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d98cb",
   "metadata": {},
   "source": [
    "## Qwen3 Support Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3b8de",
   "metadata": {},
   "source": [
    "Langchain-qwq also support qwen3 thingking model. we recomend you to import ChatQwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qwq import ChatQwen\n",
    "\n",
    "\n",
    "model = ChatQwen(model=\"qwen3-32b\", thinking_budget=100)\n",
    "\n",
    "for chunk in model.stream(\"hello!\"):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQwQ features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain-qwq/chat_models/langchain_qwq.chat_models.ChatQwQ.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
